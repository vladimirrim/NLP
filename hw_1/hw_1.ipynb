{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLemma(form):\n",
    "    if form in [\"и\", \"а\", \"но\", \"или\", \"чтобы\", \"что\", \"зато\", 'тоже']:\n",
    "        return form, \"CONJ\"\n",
    "\n",
    "    if form in [\"по\", \"в\", \"с\", \"со\", \"на\", \"у\", \"за\", \"для\", \"при\", \"через\", \"до\", \"среди\", \"между\", \"возле\"]:\n",
    "        return form, \"PR\"\n",
    "\n",
    "    if form in [\"не\", \"ни\", \"затем\", \"тогда\", \"итак\", \"наверно\", \"бы\", \"ли\", \"же\", \"вот\", \"только\", \"уже\",\n",
    "                       \"видимо\", \"потом\"]:\n",
    "        return form, \"ADV\"\n",
    "\n",
    "    if form not in formToLemma:\n",
    "        if np.random.random() > 0.3:\n",
    "            return form, 'S'\n",
    "        return form, \"ADV\"\n",
    "\n",
    "    choices = list(formToLemma[form])\n",
    "    freqs = np.array([frequencies[form][choice] if frequencies[form][choice] != 0 else 1 for choice in choices])\n",
    "    probs = freqs / sum(freqs)\n",
    "    if np.random.random() > 0.1:\n",
    "        return choices[np.argmax(probs)]\n",
    "    else:\n",
    "        return choices[np.random.choice(len(probs), 1, p=probs)[0]]\n",
    "\n",
    "\n",
    "def proccessTest(inputName, outputName):\n",
    "    with open(outputName, 'w') as output:\n",
    "        output.write('\\n'.join(proccessFile(inputName)))\n",
    "\n",
    "\n",
    "def proccessFile(filename):\n",
    "    with open(filename, 'r') as input:\n",
    "        return [processLine(line) for line in input.readlines()]\n",
    "\n",
    "\n",
    "def processLine(line):\n",
    "    tokens = line.replace(',', '').replace('.', '').replace('?', '').replace('!', '').replace('\\n', '').split(' ')\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return ' '.join([processToken(token) for token in tokens])\n",
    "\n",
    "def processToken(token):\n",
    "    lemma, part = getLemma(token)\n",
    "    return word + '{' + lemma + '=' + getCorrectPartName(part) + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrectPartName(part):\n",
    "    if part in ['ADJF', 'ADJS', 'COMP']:\n",
    "        return 'A'\n",
    "    elif part in ['NOUN']:\n",
    "        return 'S'\n",
    "    elif part in ['VERB', 'INFN', 'PRTF', 'PRTS', 'GRND']:\n",
    "        return 'V'\n",
    "    elif part in ['ADVB', 'PRCL', 'INTJ', 'PRED']:\n",
    "        return 'ADV'\n",
    "    elif part in'PREP']:\n",
    "        return 'PR'\n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictPath = '../dict.opcorpora.xml'\n",
    "corpPath = '../annot.opcorpora.no_ambig.nonmod.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = ET.parse(dictPath).getroot()\n",
    "corpus = ET.parse(corpPath).getroot()\n",
    "\n",
    "lemmas = dictionary.findall('lemmata/lemma')\n",
    "links = dictionary.findall('links/link')\n",
    "\n",
    "lemmasById = dict()\n",
    "lemmasTrueId = dict()\n",
    "formToLemma = defaultdict(set)\n",
    "\n",
    "for lemma in lemmas:\n",
    "    lemmaId = lemma.get('id')\n",
    "    lemmasTrueId[lemmaId] = lemmaId\n",
    "    lemmasById[lemmaId] = lemma\n",
    "\n",
    "for link in links:\n",
    "    toId = link.get('to')\n",
    "    fromId = link.get('from')\n",
    "    lemmasTrueId[toId] = lemmasTrueId[fromId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('odict.csv', encoding='windows-1251', newline='') as f:\n",
    "    spamreader = csv.reader(f)\n",
    "    h = defaultdict(bool)\n",
    "    nouns = ['со', 'с', 'мо-жо', 'мо', 'жо', 'мн.', 'ж', 'м', 'предик.']\n",
    "    adv = ['н', 'межд.', 'вводн.', 'част.']\n",
    "    adj = ['п', 'сравн.']\n",
    "    conj = ['союз']\n",
    "    pr = ['предл.']\n",
    "    v = ['св-нсв', 'нсв', 'св']\n",
    "    ha = defaultdict(bool)\n",
    "    for row in spamreader:\n",
    "        if row[1] in nouns:\n",
    "            formPart = 'S'\n",
    "        elif row[1] in adv:\n",
    "            formPart = 'ADV'\n",
    "        elif row[1] in conj:\n",
    "            formPart = 'CONJ'\n",
    "        elif row[1] in pr:\n",
    "            formPart = 'PR'\n",
    "        elif row[1] in adj:\n",
    "            formPart = 'A'\n",
    "        elif row[1] in v:\n",
    "            formPart = 'V'\n",
    "        else:\n",
    "            formPart = 'A'\n",
    "        for word in row[2:]:\n",
    "            formToLemma[word.lower()].add((row[0].lower(), formPart))\n",
    "        formToLemma[row[0].lower()].add((row[0].lower(), formPart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lemma in lemmas:\n",
    "    lemmaId = lemmasTrueId[lemma.get('id')]\n",
    "    mainLemma = lemmasById[lemmaId][0]\n",
    "    lemmaForm = mainLemma.get('t')\n",
    "    lemmaPart = mainLemma[0].get('v')\n",
    "    for f in lemma:\n",
    "        form = f.get('t')\n",
    "        formToLemma[form.lower()].add((lemmaForm, getCorrectPartName(lemmaPart)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = corpus.findall('./text/paragraphs/paragraph/sentence/tokens/token')\n",
    "frequencies = defaultdict(lambda: defaultdict(lambda: 1))\n",
    "\n",
    "for token in tokens:\n",
    "    form = token[0].get('t').lower()\n",
    "    lemma = token[0][0][0].get('t')\n",
    "    formPart = token[0][0][0][0].get('v')\n",
    "    frequencies[form][(lemma, getCorrectPartName(formPart))] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "proccessTest('/Users/vladimir.egorov/Downloads/dataset_37845_1.txt', 'output.txt')\n",
    "os.remove(\"/Users/vladimir.egorov/Downloads/dataset_37845_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

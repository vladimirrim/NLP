{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTextPath = '../texts_train.txt'\n",
    "trainScorePath = '../scores_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrain():\n",
    "    with open(trainTextPath) as f, open(trainScorePath) as scores:\n",
    "        return f.readlines(), scores.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "def lemmatize(sentence):\n",
    "    return m.lemmatize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:35<00:00, 569.14it/s] \n"
     ]
    }
   ],
   "source": [
    "X_lemmatized = []\n",
    "for sentence in tqdm(X):\n",
    "    X_lemmatized.append(lemmatize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def check(token):\n",
    "    return len(token) > 1\n",
    "\n",
    "def filterTokens(sentence):\n",
    "    return [token for token in sentence if check(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vladimir/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredX = [filterTokens(tokens) for tokens in  X_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tf_idfVectorization(X):\n",
    "    vectorizer = TfidfVectorizer(lowercase=True, ngram_range=(1, 3), stop_words=stopwords.words(\"russian\"))\n",
    "    x_train = vectorizer.fit_transform([' '.join(x) for x in X])\n",
    "    return vectorizer, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectrizer, vectorized = tf_idfVectorization(filteredX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    pred = np.array([str(np.clip(int(round(model.predict(xi)[0])), 1, 10)) for xi in vectorized[16000:]])\n",
    "    return np.mean(((np.array([int(pi) for pi in pred]) - np.array([int(yi) for yi in y[16000:]])) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8584\n"
     ]
    }
   ],
   "source": [
    "print(np.mean((np.array([int(yi) for yi in y]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression().fit(vectorized[:-2000], [str(int(yi) + np.random.random() * 2 - 1) for yi in y[:-2000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6695"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression().fit(vectorized[:-4000], y[:-4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9485"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge().fit(vectorized[:-2000], [str(int(yi) + np.random.random() * 2 - 1) for yi in y[:-2000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4535"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processLine(line, model):\n",
    "    x_test = vectrizer.transform([' '.join(filterTokens(lemmatize(line)))])\n",
    "    return str(np.clip(int(round(model.predict(x_test)[0])), 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testInPath = 'test.in.txt'\n",
    "testOutPath = 'test.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTest(model):\n",
    "    with open(testInPath, 'r') as input, open(testOutPath, 'w') as output:\n",
    "            for line in tqdm(input.readlines()):\n",
    "                output.write(model(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 295.62it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "processTest(lambda sentence: processLine(sentence, ridge))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
